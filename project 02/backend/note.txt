=============================================================================================================================
How to run this project:

  1)   uvicorn main:app --reload

  2nd approch is:

  2) fastapi dev
=============================================================================================================================
Annotated
The FastAPI documentation recommends the use of Annotated for 
defining route dependencies and parameters, rather than using 
Depends directly with a default value.
This approach is also suggested for various route parameters,
including Body and Cookie, as it helps ensure consistency and clarity in defining dependencies and parameters.


Example
    from fastapi import Depends, FastAPI
    app = FastAPI()
    async def common_parameters(q: str | None = None, skip: int = 0, limit: int = 100):
    return {"q": q, "skip": skip, "limit": limit}
    @app.get("/items/")
    async def read_items(commons: dict = Depends(common_parameters)):
    return commons

Use instead:
    from typing import Annotated
    from fastapi import Depends, FastAPI
    app = FastAPI()
    async def common_parameters(q: str | None = None, skip: int = 0, limit: int = 100):
    return {"q": q, "skip": skip, "limit": limit}
    @app.get("/items/")
    async def read_items(commons: Annotated[dict, Depends(common_parameters)]):
    return commons

=============================================================================================================================
inside posgresql create a table with below code :

DROP TABLE IF EXISTS todos;
DROP TABLE IF EXISTS users;

CREATE TABLE users (
  id SERIAL,
  email varchar(200) DEFAULT NULL,
  username varchar(45) DEFAULT NULL,
  firstname varchar(45) DEFAULT NULL,
  llastname varchar(45) DEFAULT NULL,
  hash_password varchar(200) DEFAULT NULL,
  is_active boolean DEFAULT NULL,
  role varchar(45) DEFAULT NULL,
  PRIMARY KEY (id)
);

DROP TABLE IF EXISTS todos;

CREATE TABLE todos (
  id SERIAL,
  title varchar(200) DEFAULT NULL,
  description varchar(200) DEFAULT NULL,
  priority integer  DEFAULT NULL,
  complete boolean  DEFAULT NULL,
  owner_id integer  DEFAULT NULL,
  PRIMARY KEY (id),
  FOREIGN KEY (owner_id) REFERENCES users(id)
);

=============================================================================================================================
Your link to connect postgresql should be like this:

SQLALCHEMY_DATABASE_URL = "postgresql://<username in postgress datbase>:<password in postgress databse >@<domain name>/<your databse name that you created in postgres>"
SQLALCHEMY_DATABASE_URL = "postgresql://user:password@127.0.0.1/Todo"
=============================================================================================================================
How to use ALEMBIC:
1) Install it
$ pip install alembic 

2) initialize it:
$ alembic init <folder that you want revisions to be saved> 
$ alembic init migrations

or for asyncrounous migrations will be :
$ alembic init -t async migrations

3) Define proect to Alempic
===>) inside alembic.ini change the datab of "sqlalchemy.url " to database that you are working with:

===>) if you use sqlite would be sth like this:
sqlalchemy.url  = "sqlite:///./database.db"

===>) if you use postgresql would be sth like this:
sqlalchemy.url = "postgresql://user:password@postgresserver/db"

4) Also we should be sure Alembic can find our models, therefore we should use "Base":
inside env.py change the value of "target_metadata"

$ from model import Base
$ target_metadata= Base.metadata

5) because we want to use migrations we dont need below line in our main.py, so we remove it:

remove below line in main.py:
$ models.Base.metadata.create_all(engine)


5) then we should do our migrations in terminal:

$ alembic revision --autogenerate -m "<your message>"

6) still oour database is not get informed about any changes in our models,
we should do below line:

$ alembic upgrade head

7) to revert to last migration:
$ alembic downgrade -l

=============================================================================================================================
How to use ALEMBIC asyncrounously:
1) Install it
$ pip install alembic 

2) initialize it:
$ alembic init -t async <folder that you want revisions to be saved> 
$ alembic init -t async migrations

3) Define proect to env.py

  import os  # noqa: F401
  import sys  # noqa: F401

  project_root = os.path.abspath(
      os.path.join(os.path.dirname(__file__), "..", "..")
  )  # noqa: F401
  sys.path.insert(0, project_root)  # noqa: F401
  from backend.db.sqlmodel_models import Seller, Shipment  # noqa: F401

  from dotenv import load_dotenv


  load_dotenv()

  POSTGRES_SERVER = os.getenv("POSTGRES_SERVER")
  POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")
  POSTGRES_USER = os.getenv("POSTGRES_USER")
  POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD")
  POSTGRES_DB = os.getenv("POSTGRES_DB")

  POSTGRES_URL = f"postgresql+asyncpg://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_SERVER}/{POSTGRES_DB}"


  config.set_main_option("sqlalchemy.url", POSTGRES_URL)

  print("o" * 35)
  print("METADATA TABLES:", list(SQLModel.metadata.tables.keys()))
  print("o" * 35)
  target_metadata = SQLModel.metadata

4) Also we should be sure Alembic can find our models, therefore we should use "Base":
inside env.py change the value of "target_metadata"

$ from ..db.sqlmodel_models import Seller, Shipment

$ target_metadata = SQLModel.metadata


4) alembic revision --autogenerate -m "<Your changes comment it with detail>"


x) Usually after autogenerate you should import sqlmodel so you dont face any problem:
import sqlmodel

xx) or instread of above commadn we can import sqlmodel inside below file name script.py.mako
in this case authomatically sqlmodel wll be imported in each migration file

5) then you should decide you want that datbase be aware of your migrations or not by below commands:
please be noted nothing will not change if we dont use below commands

$ alembic upgrade head
$ alembic downgrade -l
=============================================================================================================================
Difference between SWAGGER & SCALAR

The Problem with Default Swagger Docs
Swagger is great for getting started, but:

It's plain and developer playground-like
It doesn't scale visually when you have 50+ endpoints
It lacks branding — it doesn't feel like your product
First impressions matter — messy docs = perceived messy product
Image description

🚀 Meet scalar-fastapi
scalar-fastapi is a sweet package that upgrades your FastAPI 
documentation experience instantly.

It turns your OpenAPI schema into a:

Beautifully designed API reference
Modern, responsive UI
Developer-first experience
And the best part?

It takes just a few lines of code to integrate.

How to use scalar?

    from scalar_fastapi import get_scalar_api_reference
    app = FastAPI(title=settings.PROJECT_NAME)

    @app.get("/scalar", include_in_schema=False)
    async def scalar_html():
        return get_scalar_api_reference(
            openapi_url=app.openapi_url,
            title=app.title,
        )
=============================================================================================================================
how to orginie your imports in VScode:
press  =>  shift +  alt  +  o
=============================================================================================================================

======> session.get()
 Retrieves a single ORM object by its primary key in a simple, direct way.
Use session.get() when you need to fetch a single record by its
primary key (e.g., id).
Single Result: Returns one object or None; no need to call .scalar() or similar.

======> session.execute()
Executes a SQL query (typically a select statement) and returns a result set, 
allowing for flexible and complex queries.

Use session.execute() when you need to query based on non-primary 
key fields (e.g., email, name) or complex conditions.
Suitable for queries involving filters, joins, ordering, grouping, 
or multiple results.
Flexible Queries: Supports select statements with .where(), .join(), .order_by(), etc.
Result Handling: Returns a Result object, requiring methods like 
.scalar(), .scalar_one_or_none(), or .scalars().all() to process results.

=============================================================================================================================
how to connect to redis via windows:

frist in WSL install redis:
  sudo apy-get install redis-server

then intialize your redis server:
  sudo service redis-server restart

after that in your project in windows install redis:
  pip install redis[hiredis]

then in shell you can test that you are connected to redis or not:
  (venv) PS E:\Imparare\backend> python     
  Python 3.13.2 (tags/v3.13.2:4f8bb39, Feb  4 2025, 15:23:48) [MSC v.1942 64 bit (AMD64)] on win32
  Type "help", "copyright", "credits" or "license" for more information.
  >>> from redis import Redis
  >>> con = Redis(host='localhost', port=6379, db=0)
  >>> con.ping()
  True

  >>> con.set('key','value')
  True
  >>> con.get('key')
  b'value'
  >>> 
  
  >>> con.exists('key')
  1


=============================================================================================================================
How to fix problem with authorization via two or more url Token:


Customizes the Swagger UI to include OAuth2 security schemes (sellerAuth and partnerAuth) for seller and delivery partner authentication.
Applies security to specific endpoints (e.g., /partner/update, /partner/logout).

# 🧠 Inject custom Swagger security schemes
def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )

    openapi_schema["components"]["securitySchemes"] = {
        "sellerAuth": {
            "type": "oauth2",
            "flows": {"password": {"tokenUrl": "/seller/token", "scopes": {}}},
        },
        "partnerAuth": {
            "type": "oauth2",
            "flows": {"password": {"tokenUrl": "/partner/token", "scopes": {}}},
        },
    }
    # if "/partner/update" in openapi_schema.get("paths", {}):
    #     if "post" in openapi_schema["paths"]["/partner/update"]:
    #         openapi_schema["paths"]["/partner/update"]["post"]["security"] = [
    #             {"partnerAuth": []}
    #         ]

    # Optional: make endpoints require auth by default in Swagger
    openapi_schema["security"] = [{"sellerAuth": []}, {"partnerAuth": []}]
    openapi_schema["paths"]["/seller/dashboardv2"]["get"]["security"] = [
        {"sellerAuth": []}
    ]
    openapi_schema["paths"]["/seller/logout"]["get"]["security"] = [{"sellerAuth": []}]
    openapi_schema["paths"]["/partner/logout"]["get"]["security"] = [
        {"partnerAuth": []}
    ]
    openapi_schema["paths"]["/partner/update"]["post"]["security"] = [
        {"partnerAuth": []}
    ]

    app.openapi_schema = openapi_schema
    return app.openapi_schema


app.openapi = custom_openapi

=============================================================================================================================
What lazy="selectin" does
This affects how related data (timeline events) is loaded when you query a Shipment. Here's the behavior:

lazy="selectin" means:

SQLAlchemy will issue a separate SELECT query to fetch the related ShipmentEvent records.

BUT it’s optimized using a SELECT IN pattern — loading all relationships in one extra query for all shipments in the result set.

It’s ideal for batch loading relationships, especially when dealing with lists or pagination.

Compare that with other lazy strategies:

Lazy Strategy	Behavior	Pros	Cons
select	Loads related data in a new SELECT per parent row	Simple, predictable	Not efficient for bulk queries
joined	Uses JOIN in the same query	Fewer round-trips	Can produce large result sets, messy with pagination
subquery	Uses a subquery JOIN	Cleaner than joined	Still can be heavy
selectin	One additional query using IN	Fast, efficient in bulk	Requires proper query setup
dynamic	No automatic loading; allows .filter()	Flexible	Only usable with one-to-many, not lists in SQLModel
🧪 Example in action
Say you’re querying several Shipments:

python
shipments = session.exec(select(Shipment)).all()
With lazy="selectin" on .timeline, SQLAlchemy will:

Run one query to get all shipments.

Immediately run one extra query to get all related timeline events using a WHERE shipment_id IN (...).

Efficient and clean—and it avoids the N+1 problem (where each Shipment triggers its own timeline query).


************* compare laziness in django and fastapi models:
Django's Lazy Query Evaluation
Django ORM doesn't actually run the query when you write:

python
shipments = Shipment.objects.filter(status='delivered')
At this point, it just builds a queryset object. No SQL yet.

It waits until you evaluate the queryset — e.g. with list(), len(), iteration, template rendering, etc.

🔎 That’s why you can chain filters or annotate without triggering a DB hit until you're really ready:

python
shipments = Shipment.objects.filter(status='delivered').order_by('-created_at')[:5]
🔁 Relationship Loading (ForeignKeys, ManyToMany)
For related data, Django defaults to:

Lazy loading via separate SELECT queries per access

Similar to lazy="select" in SQLAlchemy

Triggers an extra query only when you access the related object

Example:

python
shipment = Shipment.objects.get(id=1)
event = shipment.timeline.first()  # ← Extra query fired *now*
⚡ How to load efficiently — like selectin
To mimic SQLAlchemy’s selectin loading, Django offers select_related() and prefetch_related():

Django Method	SQLAlchemy Equivalent	Best For
select_related()	joined	ForeignKey, OneToOne
prefetch_related()	selectin	ManyToMany, reverse FK
So if you’re loading a batch of shipments and want their timelines without triggering N+1:

python
shipments = Shipment.objects.prefetch_related('timeline').all()
One queryset for shipments, one optimized additional query for all related timeline events — just like selectin.

=============================================================================================================================
